# AI-learning
AI 学习使用
今天所学内容为：
对决策树中的信息熵计算公式 End(D) = Σ-p*log2(p)
决策树分类的依据是使信息熵增益的值最大，对样本集按照某一个属性分类的信息熵计算：
D：样本集
即对于样本集D在a分类条件下的信息增益为 ：Gain(D,a) = Ended（D）-Σ|Dv|/|D|*End(Dv)
Dv:D 样本集在属性a上取值为aV 的样本数
增益率：（可取值较多的属性，信息增益对可取值数目较多的属性有所偏好，因此有时使用增益看率更好）
Gain_ratio(D,a) = Gain(D，a)/IV(a),
其中IV(a)称为属性a 的固有值，IV(a) = -Σ|Dv|/|D|*log2 |Dv|/|D|
增益率对可取值数目较少的属性有所偏好，所以多变量决策树算法并不选择收益率最大的属性进行划分而是
先从候选划分属性中找出信息增益高于平均水平的属性，再从这些属性中选择增益率最高的那一项属性来进行分类
